{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, json, time\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import plotting\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from utils import imread, img_data_2_mini_batch, imgs2batch\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from naive import EncDec\n",
    "from attention import EncDec as FuseAttEncDec\n",
    "# from rnn_att import EncDec\n",
    "from data_loader import VQADataSet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5000\n",
    "dataset_filename = \"./data/data_{}.pkl\".format(N)\n",
    "dataset = None\n",
    "print(dataset_filename)\n",
    "if (os.path.exists(dataset_filename)):\n",
    "    with open(dataset_filename, 'rb') as handle:\n",
    "        print(\"reading from \" + dataset_filename)\n",
    "        dataset = pickle.load(handle)\n",
    "else:\n",
    "    dataset = VQADataSet(Q=N)\n",
    "    with open(dataset_filename, 'wb') as handle:\n",
    "        print(\"writing to \" + dataset_filename)\n",
    "        pickle.dump(dataset, handle)\n",
    "\n",
    "assert(dataset is not None)\n",
    "def debug(v,q,a):\n",
    "    print('\\nV: {}\\nQ: {}\\nA: {}'.format(v.shape, q.shape, a.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size        = 300\n",
    "hidden_size       = 1024\n",
    "batch_size        = 50\n",
    "ques_vocab_size   = len(dataset.vocab['question'])\n",
    "ans_vocab_size    = len(dataset.vocab['answer'])\n",
    "num_layers        = 1\n",
    "n_epochs          = 30\n",
    "learning_rate     = 0.001\n",
    "momentum          = 0.98\n",
    "attention_size    = 512\n",
    "debug             = False\n",
    "\n",
    "print(ques_vocab_size, ans_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data_loader, model, criterion, optimizer, batch_size, training=False,\n",
    "              epoch = 0, total_loss_over_epochs=[], scores_over_epochs=[]):\n",
    "    running_loss = 0.\n",
    "    final_labels, final_preds = [], []\n",
    "    scores, losses = [], []\n",
    "    if data_loader is None:\n",
    "        return\n",
    "    \n",
    "    run_type = None\n",
    "    if training:\n",
    "        run_type = 'train'\n",
    "        model.train()\n",
    "    else:\n",
    "        run_type = 'test'\n",
    "        model.eval()\n",
    "    \n",
    "    for i, minibatch in enumerate(data_loader):\n",
    "        # extract minibatch\n",
    "        t0 = time.time()\n",
    "        idxs, v, q, a, q_len = minibatch\n",
    "        \n",
    "        # convert torch's DataLoader output to proper format.\n",
    "        # torch gives a List[Tensor_1, ... ] where tensor has been transposed. \n",
    "        # batchify transposes back.`\n",
    "        v = v.to(device)\n",
    "        q = VQADataSet.batchify_questions(q).to(device)\n",
    "        a = a.to(device)\n",
    "\n",
    "        logits = model(v, q, q_len)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "#         loss = criterion(logits, a)\n",
    "        loss = F.nll_loss(logits, a)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "#         score = metrics.precision_recall_fscore_support(preds.tolist(),\n",
    "#                                                         a.tolist(),\n",
    "#                                                         average='weighted')\n",
    "        score = metrics.accuracy_score(preds.tolist(),a.tolist())\n",
    "    \n",
    "        scores.append(score)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        loss_key = '{}_loss'.format(run_type)\n",
    "        total_loss_over_epochs['{}_loss'.format(run_type)].append(loss)\n",
    "        scores_over_epochs['{}_scores'.format(run_type)].append(score)\n",
    "        \n",
    "        if training and optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "   \n",
    "        final_labels += a.tolist()\n",
    "        final_preds  += preds.tolist()\n",
    "        if i%10==0:\n",
    "            score = np.mean(scores)\n",
    "            print(\"Epoch {}: {} Loss: {} Score: {} t: {}\".format(epoch, run_type,loss, score, time.time()-t0))\n",
    "#             plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(7,3))\n",
    "#             plotting.plot_loss_over_n_epochs(total_loss_over_epochs, hard_key=loss_key, fig_size=(7, 3))\n",
    "            \n",
    "    return running_loss, final_labels, final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = EncDec(embed_size, hidden_size, ques_vocab_size, ans_vocab_size, rnn_layers).to(device)\n",
    "model = FuseAttEncDec(embed_size, hidden_size, attention_size, \n",
    "                      ques_vocab_size, ans_vocab_size, num_layers, debug).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.get_parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = torch.optim.Adam(model.get_parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loader = dataset.build_data_loader(train=True, args={'batch_size': batch_size})\n",
    "test_loader  = dataset.build_data_loader(test=True, args={'batch_size': batch_size})\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "train_all_loss, train_all_labels, train_all_preds = [], [], []\n",
    "print(\"model built, start training.\")\n",
    "total_loss_over_epochs, scores_over_epochs = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "total_loss_over_epochs2, scores_over_epochs2 = plotting.get_empty_stat_over_n_epoch_dictionaries()\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    t0= time.time()\n",
    "    tr_loss, tr_labels, tr_preds = eval_model(data_loader = train_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = optimizer,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = True,\n",
    "                                     epoch       = epoch,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs,\n",
    "                                     scores_over_epochs     = scores_over_epochs)\n",
    "    \n",
    "    tr_loss, ts_labels, ts_preds = eval_model(data_loader = test_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = None,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = False,\n",
    "                                     epoch       = epoch,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs2,\n",
    "                                     scores_over_epochs     = scores_over_epochs2)\n",
    "    \n",
    "    \n",
    "    score = metrics.accuracy_score(ts_preds,ts_labels)\n",
    "#     total_loss_over_epochs['train_loss'].append(tr_loss)\n",
    "#     scores_over_epochs['train_scores'].append(train_scores)\n",
    "    \n",
    "#     if True:# or epoch%1 == 0:\n",
    "    print(\"\\n\"+\"#==#\"*7 + \"epoch: {}\".format(epoch) + \"#==#\"*7)\n",
    "    print('TEST ACC: {}'.format(score))\n",
    "    print(\"#==#\"*7 + \"time: {}\".format(time.time()-t0) + \"#==#\"*7 + \"\\n\")\n",
    "#         print(train_scores)\n",
    "#     plotting.plot_score_over_n_epochs(scores_over_epochs, score_type='precision', fig_size=(8,5))\n",
    "#     plotting.plot_loss_over_n_epochs(total_loss_over_epochs, fig_size=(8, 5), title=\"Loss\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):\n",
    "    ts_loss, ts_labels, ts_preds = eval_model(data_loader = test_loader,\n",
    "                                     model       = model,\n",
    "                                     criterion   = criterion,\n",
    "                                     optimizer   = None,\n",
    "                                     batch_size  = batch_size,\n",
    "                                     training    = False,\n",
    "                                     epoch       = epoch,\n",
    "                                     total_loss_over_epochs = total_loss_over_epochs2,\n",
    "                                     scores_over_epochs     = scores_over_epochs2)\n",
    "    score = metrics.accuracy_score(ts_preds,ts_labels)\n",
    "    print(\"ACC: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "count = 1\n",
    "err_anal_data = []\n",
    "for i, minibatch in enumerate(test_loader):\n",
    "    # extract minibatch\n",
    "    t0 = time.time()\n",
    "    idxs, v, q, a, q_len = minibatch\n",
    "\n",
    "    v = v.to(device)\n",
    "    q = VQADataSet.batchify_questions(q).to(device)\n",
    "    a = a.to(device)\n",
    "    \n",
    "    logits = model(v,q,q_len)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        idx = idxs[i]\n",
    "        enc_ans = a[i].item()\n",
    "        enc_ques = q[i].detach().cpu().numpy()\n",
    "        img_v = v[i].detach().cpu().numpy()\n",
    "        question = dataset.decode_question(enc_ques)\n",
    "        answer_dec = dataset.decode_answer(preds[i])\n",
    "        answer = dataset.decode_answer(enc_ans)\n",
    "#         img_v = img_v.reshape(224, 224, 3)\n",
    "        plt.figure()\n",
    "        plt.imshow(img_v[0,:,:], interpolation='nearest')\n",
    "        plt.show()\n",
    "        question = question.replace(\"<pad>\", \"\")\n",
    "        question = question.replace(\"<start>\", \"\")\n",
    "        question = question.replace(\"<end>\", \"\").strip()\n",
    "        result = answer_dec==answer\n",
    "        err_anal_data.append([question, answer_dec, answer])\n",
    "        if not result:\n",
    "            print(\"{}. [Q] {} [A] {} [PRED] {}\".format(count, question, answer, answer_dec))\n",
    "            count+=1\n",
    "#         print(err_anal_data[-1])\n",
    "#         print('question:',  question)\n",
    "#         print(\"[{}] - predicted: {} - ground-truth: {}\".format(answer_dec==answer, answer_dec, answer))\n",
    "        \n",
    "    torch.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
